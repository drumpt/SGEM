# model
asr: facebook/wav2vec2-base-960h # facebook/wav2vec2-base-960h, speechbrain/asr-crdnn-rnnlm-librispeech, pretrained_models/stt_en_conformer_transducer_small.nemo

# dataset
dataset_name: librispeech
dataset_dir: /mnt/hdd0/changhun_workspace/LibriSpeech
split: [test-other]
batch_size: 1
extra_noise: 0

# optimizer & train hyparameters
opt: AdamW
lr: 1e-6
scheduler: null
steps: 40
train_params: all # all, feature, LN
bias_only: false
episodic: true # load pretrained model for every batch

# methods
method: original
teacher_student: true
stochastic_restoration: true
memory_queue: false

# method-specific hyperparameters
non_blank: true
reweight: true
div_coef: 0
em_coef: 1
temp: 2.5 # temperature smoothing

# logging
log_dir: exps