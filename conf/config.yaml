### model
# asr: facebook/wav2vec2-base-960h
# asr: speechbrain/asr-crdnn-rnnlm-librispeech
# asr: speechbrain/asr-crdnn-transformerlm-librispeech
asr: pretrained_models/stt_en_conformer_transducer_small.nemo
# asr: pretrained_models/stt_en_conformer_transducer_large.nemo

### dataset
# dataset_name: librispeech
# dataset_dir: /home/server17/hdd/changhun_workspace/LibriSpeech
dataset_name: chime
dataset_dir: /home/server17/hdd/changhun_workspace/CHiME3
# dataset_name: ted
# dataset_dir: /home/server17/hdd/changhun_workspace/TEDLIUM_release2/test
# dataset_name: valentini
# dataset_dir: /home/server17/hdd/changhun_workspace/Valentini
# dataset_name: commonvoice
# dataset_dir: /home/server17/hdd/changhun_workspace/cv-corpus-5.1-2020-06-22/en
split: [test-other]
extra_noise: 0.00
noise_type: null  # currently supported: null, AirConditioner_6, AirportAnnouncements_2, Babble_4, CopyMachine_2, Munching_3, Neighbor_6, ShuttingDoor_6, Typing_2, VacuumCleaner_1
sample_rate: 16000
batch_size: 1

### device
device: cuda

### logging
log_dir: exps/test

### optimizer & train hyparameters
optimizer: AdamW
scheduler: null
lr: 2e-5
steps: 10
train_params: [all] # currently supported: all, feature, LN, linear(linear probing), da
bias_only: false
episodic: true # load pretrained model for every batch

##################################################################
### methods & other hyperparameters
method: [beam_search_max] # currently supported: original, em_uncertainty, em_sparse, em_joint, em_aug, p_logp, cr, cr_feature, da, contrastive_temporal, memo_dropout, gce, ctc, mixup, beam_search_max, beam_search_all, beam_search_negative_sampling, beam_em_mix, diversity_maximization, beam_search_em
temp: 2.5 # temperature smoothing
not_blank: true
certain_only: true
em_coef: 0.3
reweight: true

# TODO: use this for implementing greedy search and beam search
forward_method: greedy # greedy or beam_search

### augmentation for consistency regularization
num_augs: 1
aug_method: augmix # augmix, standard

### beam search and negative sampling
beam_width: 10
num_negatives: 0

ns_coef: 0.1
negative_sampling_method: beam_candidate # random, beam_candidate

### diversity maximization
dm_coef: 0.1

### uncertainty aware pseudo-labeling
prob_threshold: 0.9
entropy_threshold: 0.05
##################################################################

### selective adaptation
selective_adaptation: false
ood_threshold: -0.45

### memory queue
use_memory_queue: false
queue_method: latest # currently supported: random, latest, informative, similar
queue_size: 3
n_neighbors: 3

### teacher-student model for non episodic adaptation
teacher_student: false
momentum: 0.99

### restore pretrained model for non-episodic adaptation
stochastic_restoration: false
restore_prob: 0.01

### seed for reproductivity
seed: 42