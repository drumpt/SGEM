# model
asr: facebook/wav2vec2-base-960h
# asr: speechbrain/asr-crdnn-rnnlm-librispeech
# asr: pretrained_models/stt_en_conformer_transducer_small.nemo

# dataset
# dataset_name: librispeech
# dataset_dir: /home/server28/ssd/changhun_workspace/nfs-client/LibriSpeech
dataset_name: chime
dataset_dir: /home/server28/ssd/changhun_workspace/nfs-client/CHiME3
# dataset_name: commonvoice
# dataset_dir: /home/server28/ssd/changhun_workspace/nfs-client/cv-corpus-5.1-2020-06-22/en
# dataset_name: ted
# dataset_dir: /home/server28/ssd/changhun_workspace/nfs-client/TEDLIUM_release2/test
split: [test-other]
extra_noise: 0.01
sample_rate: 16000
batch_size: 1

# optimizer & train hyparameters
optimizer: AdamW
scheduler: null
lr: 2e-5
steps: 1
train_params: [feature] # currently supported: all, feature, LN, linear(linear probing), da
bias_only: false
episodic: true # load pretrained model for every batch

# methods & other hyperparameters
method: [em_joint] # currently supported: original, em_uncertainty, em_sparse, em_joint, em_aug, p_logp, cr, cr_feature, da, contrastive_temporal
temp: 2.5 # temperature smoothing
em_coef: 1
div_coef: 0
num_augs: 1
aug_method: augmix # augmix, standard
not_blank: true
reweight: true

# memory queue
use_memory_queue: true
queue_method: similar # currently supported: random, latest, informative, similar
queue_size: 16
n_neighbors: 3

# selective adaptation
selective_adaptation: false
ood_threshold: -0.45

# uncertainty aware entropy minimization
prob_threshold: 0.9
entropy_threshold: 0.05

# teacher student model for non episodic adaptation
teacher_student: false
momentum: 0.99

# restore pretrained model for non episodic adaptation
stochastic_restoration: false
restore_prob: 0.01

# device
device: cuda

# logging
log_dir: exps/test